{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c1fbdd-c991-40a8-a9dc-018bbc6ba779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.68</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power  Voltage  \\\n",
       "Date                                                                       \n",
       "2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
       "2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
       "2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
       "2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
       "2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "Date                                                                    \n",
       "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
       "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
       "2006-12-16 17:27:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:28:00              15.8             0.0             1.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "Date                                 \n",
       "2006-12-16 17:24:00            17.0  \n",
       "2006-12-16 17:25:00            16.0  \n",
       "2006-12-16 17:26:00            17.0  \n",
       "2006-12-16 17:27:00            17.0  \n",
       "2006-12-16 17:28:00            17.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# stats\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf, month_plot, quarter_plot\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = [20, 5]\n",
    "\n",
    "# settings\n",
    "color_pal = sns.color_palette()\n",
    "\n",
    "def join_date_and_time(df):\n",
    "    df = df.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S')\n",
    "    df = df.drop(['Time'], axis=1)\n",
    "    return df\n",
    "\n",
    "def clean(df):\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        #df = df[~df[col].str.contains('?', regex=False)]\n",
    "        df[col] = df[col].str.replace('?', 'nan', regex=False).astype(float)\n",
    "        df = df.fillna(method='ffill')\n",
    "    return df\n",
    "\n",
    "def create_time_series_features(df):\n",
    "    df['hour'] = df.index.hour\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    return df\n",
    "\n",
    "FILE_PATH = 'data/household_power_consumption.txt'\n",
    "\n",
    "df = pd.read_csv(FILE_PATH, delimiter=';', dtype=str)\n",
    "df = join_date_and_time(df)\n",
    "df = df.set_index('Date')\n",
    "df = clean(df)\n",
    "#df['Sub_metering_4'] = (df['Global_active_power'] * 1000 / 60) - (df['Sub_metering_1'] + df['Sub_metering_2'] + df['Sub_metering_3'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e997119c-5068-43dc-b8d7-8879933a5565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import torch\n",
    "\n",
    "transformer = RobustScaler().fit(df)\n",
    "processed_features = transformer.transform(df)\n",
    "processed_features = pd.DataFrame(processed_features, columns=df.columns)\n",
    "df = processed_features.set_index(df.index)\n",
    "\n",
    "hourly_resampled_df = create_time_series_features(df.resample('H').mean())\n",
    "daily_resampled_df = create_time_series_features(df.resample('D').mean())\n",
    "\n",
    "column = 'Global_active_power'\n",
    "\n",
    "hourly_shifted_df = hourly_resampled_df.copy()\n",
    "daily_shifted_df = daily_resampled_df.copy()\n",
    "\n",
    "hourly_shifted_df[column] = hourly_shifted_df[column].shift(-1)\n",
    "daily_shifted_df[column] = daily_shifted_df[column].shift(-1)\n",
    "\n",
    "hourly_shifted_df.loc[hourly_shifted_df.index[-1], 'Global_active_power'] = 0.0\n",
    "daily_shifted_df.loc[daily_shifted_df.index[-1], 'Global_active_power'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f6998f7-d263-4c28-8ba1-215595549c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"Global_reactive_power\",\"Voltage\",\"Global_intensity\",\"Sub_metering_1\",\"Sub_metering_2\",\"Sub_metering_3\",\"hour\",\"dayofweek\",\"quarter\",\"month\",\"year\",\"dayofyear\"]\n",
    "\n",
    "TARGET = [\"Global_active_power\"]\n",
    "\n",
    "train_df = hourly_shifted_df[:'2009-12-31'].fillna(0.0)\n",
    "test_df = hourly_resampled_df['2010-01-01':].fillna(0.0)\n",
    "\n",
    "X_train = train_df[FEATURES]\n",
    "y_train = train_df[TARGET] \n",
    "\n",
    "X_test = test_df[FEATURES]\n",
    "y_test = test_df[TARGET] \n",
    "\n",
    "X_train = torch.tensor(X_train.values.astype(np.float32))\n",
    "y_train = torch.tensor(y_train.values.astype(np.float32))\n",
    "\n",
    "X_test = torch.tensor(X_test.values.astype(np.float32))\n",
    "y_test = torch.tensor(y_test.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d6a90b8-caf0-4f7b-bb06-6d8f4dcc3dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 50, epochs: 400, batch: -\n",
      "RMSE: 0.7195882201194763, MAE: 0.42574596405029297, MAPE: 4.156902313232422 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class EnergyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=12, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50,1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "model = EnergyModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "#loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=1000)\n",
    "\n",
    "# RNN is not yet implemented on Mac silicon processor\n",
    "#device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "#model.to(device)\n",
    "\n",
    "epoch_count = []\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "epochs = 400\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    #for X_batch, y_batch in loader:\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred = model(X_test)\n",
    "        test_loss = loss_fn(y_pred, y_test)\n",
    "        \n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(loss.detach().numpy())\n",
    "        test_loss_values.append(test_loss.detach().numpy())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test.detach().numpy(), y_pred.detach().numpy(), squared=False)\n",
    "mae = mean_absolute_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "mape = mean_absolute_percentage_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "\n",
    "print(\"hidden_size: 50, epochs: 400, batch: -\")\n",
    "print(f\"RMSE: {np.sqrt(mse)}, MAE: {mae}, MAPE: {mape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f272f6d2-9ef9-4ba7-ac10-074fe13b5440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 50x50, epochs: 400, batch: -\n",
      "RMSE: 0.6189409494400024, MAE: 0.28782814741134644, MAPE: 2.642587184906006 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class EnergyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=12, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.deep_lstm = nn.LSTM(input_size=50, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50,1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x, _ = self.deep_lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "model = EnergyModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "#loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=1000)\n",
    "\n",
    "# RNN is not yet implemented on Mac silicon processor\n",
    "#device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "#model.to(device)\n",
    "\n",
    "epoch_count = []\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "epochs = 400\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    #for X_batch, y_batch in loader:\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred = model(X_test)\n",
    "        test_loss = loss_fn(y_pred, y_test)\n",
    "        \n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(loss.detach().numpy())\n",
    "        test_loss_values.append(test_loss.detach().numpy())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test.detach().numpy(), y_pred.detach().numpy(), squared=False)\n",
    "mae = mean_absolute_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "mape = mean_absolute_percentage_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "\n",
    "print(\"hidden_size: 50x50, epochs: 400, batch: -\")\n",
    "print(f\"RMSE: {np.sqrt(mse)}, MAE: {mae}, MAPE: {mape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9894a46c-84cb-4a7f-86a6-f715b05db849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 50x50x50x50, epochs: 400, batch: -\n",
      "RMSE: 0.7640368938446045, MAE: 0.4481506645679474, MAPE: 3.9662024974823 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class EnergyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=12, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.deep_lstm = nn.LSTM(input_size=50, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50,1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x, _ = self.deep_lstm(x)\n",
    "        x, _ = self.deep_lstm(x)\n",
    "        x, _ = self.deep_lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "model = EnergyModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "#loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=1000)\n",
    "\n",
    "# RNN is not yet implemented on Mac silicon processor\n",
    "#device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "#model.to(device)\n",
    "\n",
    "epoch_count = []\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "epochs = 400\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    #for X_batch, y_batch in loader:\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred = model(X_test)\n",
    "        test_loss = loss_fn(y_pred, y_test)\n",
    "        \n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(loss.detach().numpy())\n",
    "        test_loss_values.append(test_loss.detach().numpy())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test.detach().numpy(), y_pred.detach().numpy(), squared=False)\n",
    "mae = mean_absolute_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "mape = mean_absolute_percentage_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "\n",
    "print(\"hidden_size: 50x50x50x50, epochs: 400, batch: -\")\n",
    "print(f\"RMSE: {np.sqrt(mse)}, MAE: {mae}, MAPE: {mape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b8e0ffc-ee47-47f9-bd0f-0980f42df90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 50x50x1x50x50, epochs: 400, batch: -\n",
      "RMSE: 0.7542456388473511, MAE: 0.47223737835884094, MAPE: 6.151860237121582 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class EnergyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=12, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.deep_lstm = nn.LSTM(input_size=50, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.deep_linear = nn.Linear(50,50)\n",
    "        self.linear = nn.Linear(50,1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x, _ = self.deep_lstm(x)\n",
    "        x = self.deep_linear(x)\n",
    "        x, _ = self.deep_lstm(x)\n",
    "        x, _ = self.deep_lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "     \n",
    "torch.manual_seed(42)\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "model = EnergyModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "#loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=1000)\n",
    "\n",
    "# RNN is not yet implemented on Mac silicon processor\n",
    "#device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "#model.to(device)\n",
    "\n",
    "epoch_count = []\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "epochs = 400\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    #for X_batch, y_batch in loader:\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred = model(X_test)\n",
    "        test_loss = loss_fn(y_pred, y_test)\n",
    "        \n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(loss.detach().numpy())\n",
    "        test_loss_values.append(test_loss.detach().numpy())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test.detach().numpy(), y_pred.detach().numpy(), squared=False)\n",
    "mae = mean_absolute_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "mape = mean_absolute_percentage_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "\n",
    "print(\"hidden_size: 50x50x1x50x50, epochs: 400, batch: -\")\n",
    "print(f\"RMSE: {np.sqrt(mse)}, MAE: {mae}, MAPE: {mape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1744869f-42f8-48e1-9939-f931b56fd465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 50x50, epochs: 50, batch: 1000\n",
      "RMSE: 0.5498433113098145, MAE: 0.21881520748138428, MAPE: 2.246748924255371 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class EnergyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=12, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.deep_lstm = nn.LSTM(input_size=50, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50,1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x, _ = self.deep_lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "model = EnergyModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=1000)\n",
    "\n",
    "# RNN is not yet implemented on Mac silicon processor\n",
    "#device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "#model.to(device)\n",
    "\n",
    "epoch_count = []\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 10 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred = model(X_test)\n",
    "        test_loss = loss_fn(y_pred, y_test)\n",
    "        \n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(loss.detach().numpy())\n",
    "        test_loss_values.append(test_loss.detach().numpy())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test.detach().numpy(), y_pred.detach().numpy(), squared=False)\n",
    "mae = mean_absolute_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "mape = mean_absolute_percentage_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "\n",
    "print(\"hidden_size: 50x50, epochs: 50, batch: 1000\")\n",
    "print(f\"RMSE: {np.sqrt(mse)}, MAE: {mae}, MAPE: {mape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14a26dc2-a4f1-45f4-9532-2e53f13bbcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 50x50, epochs: 50, batch: 1000\n",
      "RMSE: 0.5535768270492554, MAE: 0.22418361902236938, MAPE: 2.096618175506592 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class EnergyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=12, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.deep_linear = nn.Linear(50,25)\n",
    "        self.deep_lstm = nn.LSTM(input_size=25, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50,1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.deep_linear(x)\n",
    "        x, _ = self.deep_lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "model = EnergyModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=1000)\n",
    "\n",
    "# RNN is not yet implemented on Mac silicon processor\n",
    "#device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "#model.to(device)\n",
    "\n",
    "epoch_count = []\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 10 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred = model(X_test)\n",
    "        test_loss = loss_fn(y_pred, y_test)\n",
    "        \n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(loss.detach().numpy())\n",
    "        test_loss_values.append(test_loss.detach().numpy())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test.detach().numpy(), y_pred.detach().numpy(), squared=False)\n",
    "mae = mean_absolute_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "mape = mean_absolute_percentage_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "\n",
    "print(\"hidden_size: 50x50, epochs: 50, batch: 1000\")\n",
    "print(f\"RMSE: {np.sqrt(mse)}, MAE: {mae}, MAPE: {mape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283aeec4-c47b-4118-91fd-16df527ec1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class EnergyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.GRU(input_size=12, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.deep_lstm = nn.GRU(input_size=50, hidden_size=50, num_layers=1, batch_first=True)\n",
    "        self.linear = nn.Linear(50,1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x, _ = self.deep_lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "torch.manual_seed(42)\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "model = EnergyModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=1000)\n",
    "\n",
    "# RNN is not yet implemented on Mac silicon processor\n",
    "#device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "#model.to(device)\n",
    "\n",
    "epoch_count = []\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 10 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred = model(X_test)\n",
    "        test_loss = loss_fn(y_pred, y_test)\n",
    "        \n",
    "        epoch_count.append(epoch)\n",
    "        train_loss_values.append(loss.detach().numpy())\n",
    "        test_loss_values.append(test_loss.detach().numpy())\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test.detach().numpy(), y_pred.detach().numpy(), squared=False)\n",
    "mae = mean_absolute_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "mape = mean_absolute_percentage_error(y_test.detach().numpy(), y_pred.detach().numpy())\n",
    "\n",
    "print(\"hidden_size: 50x50, epochs: 50, batch: 1000\")\n",
    "print(f\"RMSE: {np.sqrt(mse)}, MAE: {mae}, MAPE: {mape} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
